{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrain Best ML Model on Combined Train+Eval Data\n",
    "\n",
    "In this notebook we retrain our best performing ML model (CatBoost with combined tabular and text features) on the combined training and evaluation datasets. This allows us to leverage all available data for the final model while maintaining proper test set separation."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from graildient_descent.model import Model\n",
    "from graildient_descent.utils import set_random_seed"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "load_dotenv()\n",
    "random_state = set_random_seed()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Load Train and Eval Data"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Load train and eval datasets\n",
    "train_data = pd.read_csv(\"../data/splits/25k/train_25k.csv\")\n",
    "eval_data = pd.read_csv(\"../data/splits/25k/eval_25k.csv\")\n",
    "\n",
    "# Combine datasets\n",
    "combined_data = pd.concat([train_data, eval_data], ignore_index=True)\n",
    "\n",
    "# Prepare features and target\n",
    "X = combined_data.drop(columns=[\"sold_price\", \"id\", \"parsing_date\"])\n",
    "y = combined_data[\"sold_price\"]\n",
    "y_log = np.log1p(y)  # Log transform target as per best configuration"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Initialize Best Model Configuration"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Configure best model parameters based on experiments\n",
    "model_configs = {\n",
    "    \"model_name\": \"catboost_v1\",\n",
    "    \"estimator_class\": \"catboost\",\n",
    "    \"use_tab_features\": True,\n",
    "    \"use_text_features\": True,\n",
    "    \"transformer_params\": {\n",
    "        \"catboost_cols\": [\n",
    "            \"designer\",\n",
    "            \"color\",\n",
    "            \"size\",\n",
    "            \"subcategory\",\n",
    "        ],  # Mid/high cardinality features\n",
    "        \"ohe_cols\": [\"department\", \"category\"],  # Low cardinality features\n",
    "        \"oe_cols\": [\"condition\"],  # Ordinal feature\n",
    "    },\n",
    "    \"extractor_params\": {\n",
    "        \"vectorizer_class\": \"tfidf\",\n",
    "        \"vectorizer_params\": {\"ngram_range\": (1, 3), \"min_df\": 5},\n",
    "        \"reducer_class\": \"pca\",\n",
    "        \"reducer_params\": {\"n_components\": 100},\n",
    "    },\n",
    "}"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Train and Save Final Model"
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Initialize model\n",
    "model = Model(**model_configs)\n",
    "\n",
    "# Train model on combined data\n",
    "model.fit(X, y_log)\n",
    "\n",
    "# Create directory for best models\n",
    "os.makedirs(\"../models/benchmarks/\", exist_ok=True)\n",
    "\n",
    "# Save model\n",
    "model.save_model(\"../models/benchmarks/\")\n",
    "print(f\"Model saved to 'models/benchmarks/{model_configs['model_name']}.pkl'\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
